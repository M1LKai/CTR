数据处理
  1，探索性分析
    本文的数据来自于2018年科大讯飞AI营销算大赛的初赛以及复赛数据，本次大赛提供了科大讯飞AI营销云的海量的广告数据和用户数据，
  本论文将结合此数据讨论如何有效利用这些数据去通过人工智能技术构建预测模型预估用户的广告点击概率，
  即给定广告点击相关的广告、媒体、用户、上下文内容等信息的条件下预测广告点击概率。
    数据内容主要分为两个两个量级不同的数据集，其中包括包含用户id的基本信息，还有广告信息类、媒体信息类、用户信息类、上下文信息类。
  首先对数据进行基本处理，读取并将初复赛的数据融合，一共包含有35个字段的3080276条记录，其中有bool类型字段6个，float类型字段2个, 
  int类型字段18, object类型9个；其中训练集与测试集之间没有交集，训练集正负样本比例大致为1/4（如图）；整个数据集中user_tags，make，model，osv，app_cate_id，f_channel，app_id这7个字段含有缺失值。
    接下来对每个字段进行单独分析处理。首先针对广告id进行处理，训练集内删去重复值后有2187个广告id，
  共有3000000条关于adid的记录，最多一个广告id有124653条记录，最低1条，平均每个广告id含有1372条记录。
  通过对广告记录数对应广告量的散点图（figure1）分析，大部分广告还是集中在点击量比较少的区域；
  训练集拥有39个广告主id的3000000条记录，分析发现广告主的点击率之间相差较大，但是不同广告主的曝光次数也差异比较大不可确定差异是否与之有关，
  故进行卡方检验，可得P值小于0.05，有显著的统计学意义，即广告主对用户点击率有积极的影响作用；
  训练集时间字段共有2187，最大的重复字段为62个，但是由于过于但是时间字段与点击率相关的主要为hour部分，所以进行更细致的切分，
  通过曝光量与点击量的时间柱形图，可以看出与每天时间变化存在一定的关系。
    其他字段处理还包括：908个订单id与其他7个字段对应；活动id与广告主id唯一对应；34个广告主名称对应38个广告主id，但都不是有缺失的特征
  广告主名称与广告主id不是一一对应，id底下唯一对应一个名字，名字不唯一对应一个id，所以一个广告主名字可能有多个id；创意高和创意宽都会
  影响到点击率的大小；也有很多的相关点击率是100%，明显是由于基数过大与过少，这样的数据不具有泛化能力；
  手机品牌与机型太多，粒度太细容易过拟合，所以在后续操作中可能采取合并手机类型的做法。
；还包括其他一些的处理，有些一对一的特征，在之后的预测过程中可以考虑删去其中之一。
  2，数据预处理
     2.1数据清洗 Data Cleansing
          本次数据分为初赛与复赛的测试集与训练集四部分数据，首先将数据集融合到一起，统一进行去重处理。
       数据清洗时，首先对时间的特征进行分箱处理，将一天划分为四个时间段，时间段与点击量的情况(如图)可以通过观察到，后续还可以考虑
       时间每天对于点击率的影响；由于数据在又有操作系统又有操作系统的版本，既包含了品牌又含有设备类型等等，其中包含了比较多的重复信息，
       对操作系统及其版本、名称进行处理，版本数据进行更进一步的细分，对品牌和机型的数据清洗；对上下文信息，媒体信息以及广告信息中部分特征值
       进行交叉，可以生成更细粒度的交叉特征，然后再将交叉特征与重要特征进行组合；对于存在缺失值的特征字段使用fillna函数进行缺失值补充；使用
       labelencoder函数对除用户标签以外的类别特征进行Labelencoder编码；数据中的布尔型特征应该更改为数值型，所以采用replace函数完成。

特征工程
  1，特征选择方法介绍
        
       
  2，本论文特征选择
         nunique特征
         user_tags CountVectorize
         add nunique feature
         add ctr feature
      
算法模型
  1，CTR常用模型介绍
        lr(Logistic Regression)
        fm与ffm
        GBDT
        基于FTRL的online learning
        MLR
        DIN
  2，本论文采用模型
        本论文首先采用较为传统的模型进行训练。第一采用了曾经在泰坦尼克号事件相关预测所使用过的随机森林模型进行尝试，
      然后有使用的CTR预测的基础模型逻辑回归进行模型训练及预测。两次尝试最终的效果都比较差，与预期有较大的差距，并且处理
      较大规模数据速度太慢，在CTR预测中不太适用。
        根据尝试结果及其他模型的学习结论，综合考虑较好的数据处理效率和准确性，决定采用在大量预测点击率和搜索排序都
      表现不错的GBDT模型进行训练，GBDT采用Boosting思想每次分类都会迭代产生更强的分类器，并且还具有比较好的记忆能力和特征筛选能力，
      所以在本次CTR预测的实例中表现不错。而在GBDT的工程实现中，则是选择了Light Gradient Boosting Machine (LightGBM)，
      它是一个由微软亚洲研究院分布式机器学习工具包（DMTK）团队开源的基于GBDT的框架。
      lightGBM不仅仅可以处理大规模数据，甚至还有更快的训练速度和效率，对于内存的使用也比较小，
      最吸引人的是最终模型的准确率也是有保障，同时还支持并行化的学习。
          lightGBM主要是进行了重心位于模型训练速度的优化。首先，lightGBM采用单边梯度采样算法(Grandient-based One-Side Sampling，GOSS)
       LightGBM使用GOSS算法对训练样本采样过程进行优化。在GBDT的基本算法中是没有关于样本的权重，
       所以LightGBM采用了基于每一个样本的梯度进行训练样本的优化，数据拥有较大梯度的时候对计算信息增益的贡献比较大。
       当一个样本点的梯度很比较小的时候，就说明该样本的训练误差其实很小，即该样本已经被充分训练。
       然而如果单纯在计算过程中，仅仅保留梯度较大的样本，抛弃梯度较小样本，这样的做法会改变样本的分布并且降低学习的精度。GOSS算法的提出就是针对这个问题，
       GOSS算法的基本思想是根据梯度首先对训练集数据排序，并且预设一个恰当的比例，保留在所有样本中梯度高于的数据样本；
       梯度低于该比例的数据样本也不会被直接丢弃，而是设置一个采样比例，从梯度较小的样本中按比例抽取样本。
       同时为了弥补对样本分布造成的影响，GOSS算法在计算信息增益时，会对较小梯度的数据集乘以一个系数，用来放大。
       这样，在计算信息增益时，算法就会去更加注意还未被充分训练的样本数据；
       除此之外，lightGBN还有一个很重要的算法Exclusive Feature Bundling算法(EFB)。lightGBM不仅优化了采集样本的过程，还进行特征抽取，
       特征抽取与特征提取不同，特征抽取并不减少训练时数据特征向量的维度，而是通过将互斥特征通过一定的算法绑定在一起，从而减少特征维度。
       数据中互斥特征被绑定在一起后，就会形成低维的特征集合，这使得模型能够有效的避免那些对0值特征的不必要计算。
       实际上，在算法中，这就可以有效的降低创建直方图的时间复杂度，从而快速过渡到下一个优化算法直方图算法（Histogram算法),相对于极端梯度提升（eXtreme Gradient Boosting，XGBoost）
       采用的需要进行提前排序的exact算法，Histogram算法能减少内存消耗，还能做减差加速作用。
       lightGBM中一个子节点的直方图可以通过父节点的直方图减去兄弟节点的直方图即可得到，从而实现加速，并且实际的数据集上表明，
       离散化的分裂点对最终学习的精度影响并不大，甚至会更好一些。
       因为这里的决策树本身就是弱学习器，采用Histogram离散化特征值反而会起到正则化的效果，从而提高算法的泛化能力；lightGBM采用的
       分支策略为按叶子生长（leaf-wise）的策略，相对于大多数按层生长（level-wise)的策略，这种策略更加高效，
       该策略每次从当前决策树所有的叶子节点中，找到分裂增益最大的一个叶子节点，然后分裂，如此循环往复。
       这样的机制下，减少了对增益较低的叶子节点的分裂计算，减少不必要的开销。
       与leve-wise的策略相比，在分裂次数相同的情况下，leaf-wise对误差处理效果更好，能有效降低误差得到更好的精度。
       Leaf-wise算法有一个缺点就是可能会生成较深的决策树，因此，LightGBM在Leaf-wise上增加了限制最大深度的参数，既能保证算法高效的同时，还能防止过拟合。
             实际建模过程中，在将数据导入模型前，由于设备的限制也是为了模型训练速度的提高，提高删除数据中一些无用的特征，，再将训练集与测试集
       提取出来。之后再将已经提取出来的用户的词向量特征通过hstack函数组合到训练集与测试集；模型调参使用的是网格搜索(Grid Search)的方法，
       每次确定其中的两个参数能够使得模型达到最好的数值，不断迭代得到最终的参数组合。lightGBM的进一步调优过程中，使用了K折交叉验证，
       通过自己对十折交叉验证和五折交叉验证两个取值的检验，五折交叉验证有着更好的表现，
       通过五折交叉检验的优化过程可以得到了五个模型及对应的预测结果，最终再将结果加权平均或者调和平均即可完成。
             二分类模型的结果评价一般采用ROC曲线和AUC，或是损失函数(logloss)。对于CTR预测的模型结果评价则是一般采用后者，所以可能将五折交叉验证
        所得的结果进行调和平均可能会有更好的效果


总结与思考
        本次数据使用中，大多数重要信息都得到了较好的利用，但是对于其中用户id这一关键信息由于缺少信息介绍，在使用过程中没有多大意义，没有很好的
      帮助了解用户的情况，对模型预测来说是一个极大的损失。
        减少内存的方法有待改进，在完成项目后网上发现有人采用Stacking的方式，在提取一些新的特征的同时又减低内存要求，最大限度保存所有特征的
      区分度信息的同时减少特征维度。
        对于数据的处理还是耗费了大量的时间，所以模型的选取，优化及更多模型交叉融合检验的工作做得较少，这次的预测结果也是有很多待提升的地方，
      特别是一些最新的关于深度学习方面的模型成果可以用来尝试
        本次研究过程中，考虑数据量不是非常庞大的情况，所以仅仅采用模型训练速度更快的lightGBM来实现GBDT，如果今后需要处理更庞大的数据集的时候
      可以考虑将lightGBM与XGBoost结合起来，lightGBM作为基础模型，发挥其处理数据更有优秀的特点，再将结果导入XGBoost的二级模型，XGBoost模型
      处理速度不及lightGBM，但是预测结果更加准确。
         通过这次研究不仅关于关于点击率预测相关知识有了进一步的了解，还有很多包括模型的发展，构建以及优化的各方面有了进一步的提升，也会明白
      有很多还没学习过的知识。本次项目也没有使用创新的模型，同时也是没有进行更多模型的融合尝试，以后的项目执行过程中需要考略这类问题。

